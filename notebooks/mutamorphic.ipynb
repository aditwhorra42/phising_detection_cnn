{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urlunparse\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "from ml_lib_remla.preprocessing import Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_DATAPOINTS = 1000\n",
    "DATASET_PATH = \"./../data/DL Dataset/test.txt\"\n",
    "MODEL_PATH = \"./../model/model.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path: str):\n",
    "    \"\"\"Loads the data split from the path. The path should be a .txt file that\n",
    "    has been created from the get_data step. his should be stored in the data folder.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): The path to the split .txt file.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], List[str]]: Returns a tuple of raw_x and raw_y. raw_x is a\n",
    "        list of strings for all the sentences in the split and raw_y is their corresponding label.\n",
    "    \"\"\"\n",
    "    print(f\"Loading dataset: {data_path}\")\n",
    "\n",
    "    try:\n",
    "        with open(data_path, \"r\") as data_file:\n",
    "            loaded_data = [line.strip() for line in data_file.readlines()[1:]]\n",
    "    except FileNotFoundError as file_not_found_error:\n",
    "        raise FileNotFoundError(f\"Could not find file {data_path}.\") from file_not_found_error\n",
    "    except OSError as exception:\n",
    "        raise OSError(f\"An error occurred accessing file {data_path}: {exception}\") from exception\n",
    "\n",
    "    raw_x = [line.split(\"\\t\")[1] for line in loaded_data]\n",
    "    raw_y = [line.split(\"\\t\")[0] for line in loaded_data]\n",
    "    return raw_x, raw_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: ./../data/DL Dataset/test.txt\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = load_dataset(DATASET_PATH)\n",
    "X_test = X_test[:N_DATAPOINTS]\n",
    "y_test = y_test[:N_DATAPOINTS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "\u001b[1m90/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step"
     ]
    }
   ],
   "source": [
    "def test_input_generation(urls):\n",
    "    # Parse the URLs from the input list\n",
    "    parsed_urls = [urlparse(url) for url in X_test]\n",
    "\n",
    "    def replace_scheme(scheme):\n",
    "        # Replace the scheme of the URL\n",
    "        if scheme == 'http':\n",
    "            return 'https'\n",
    "        elif scheme == 'https':\n",
    "            return 'http'\n",
    "        else:\n",
    "            return scheme\n",
    "\n",
    "    def replace_tld(netloc, tld):\n",
    "        # Replace the top-level domain (TLD) in the netloc\n",
    "        tld_pattern = re.compile(r'\\.(com|org|de|net|uk|us|mobi|co\\.uk|gov|edu|io|ai|dev|biz|info|mil|int|arpa)\\b', re.IGNORECASE)\n",
    "        new_netloc = tld_pattern.sub(lambda match: '.' + tld.lstrip('.'), netloc)\n",
    "        return new_netloc\n",
    "\n",
    "    tld_list = ['.io', '.ai', '.dev']\n",
    "\n",
    "    # Generate mutant candidates by replacing scheme and TLD\n",
    "    parsed_urls_scheme = [url._replace(scheme=replace_scheme(url.scheme)) for url in parsed_urls]\n",
    "    parsed_urls_scheme_tld = [url._replace(scheme=replace_tld(url.netloc, tld=tld)) for url in parsed_urls_scheme for tld in tld_list]\n",
    "\n",
    "    # Filter out empty mutants\n",
    "    mutated_urls = np.array([urlunparse(url) for url in parsed_urls_scheme_tld if urlunparse(url) != \"\"])\n",
    "\n",
    "    return mutated_urls\n",
    "\n",
    "def test_oracle_generation(y_pred_original, y_pred_mutant, threshold=0.5):\n",
    "    n_mutants = len(y_pred_mutant) // len(y_pred_original)\n",
    "    y_pred_original = y_pred_original.flatten()\n",
    "    y_pred_mutant = y_pred_mutant.reshape(len(y_pred_original), n_mutants).T\n",
    "\n",
    "    labels_original = (np.array(y_pred_original) > threshold).astype(int)\n",
    "    labels_mutant = (np.array(y_pred_mutant) > threshold).astype(int)\n",
    "    \n",
    "    failing_tests = np.argwhere(labels_original != labels_mutant)\n",
    "    \n",
    "    return failing_tests \n",
    "\n",
    "def inconsistency_repair(y_pred_original, y_pred_mutant, failing_tests):\n",
    "    # Perform inconsistency repair (placeholder function)\n",
    "    return failing_tests\n",
    "\n",
    "def test_mutamorphic(X_orig):\n",
    "    # Generate mutant candidates\n",
    "    mutant_candidates = test_input_generation(X_orig)\n",
    "\n",
    "    preprocessor = Preprocessing()\n",
    "    X_orig = preprocessor.tokenize_batch(X_orig)\n",
    "    X_mutator = preprocessor.tokenize_batch(mutant_candidates)\n",
    "\n",
    "    model = load_model(MODEL_PATH)\n",
    "    y_pred_original = model.predict(X_orig)\n",
    "    y_pred_mutant = model.predict(X_mutator)\n",
    "\n",
    "    failing_tests = test_oracle_generation(y_pred_original, y_pred_mutant)\n",
    "    \n",
    "    return failing_tests\n",
    "\n",
    "# Perform mutamorphic testing and assert the number of failing tests\n",
    "failing_tests = test_mutamorphic(X_orig=X_test)\n",
    "print(failing_tests)\n",
    "assert len(failing_tests) < len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
